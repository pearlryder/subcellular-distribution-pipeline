{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import and define parameters\n",
    "\n",
    "Below, you will define the basic parameters for your database and subcellular structures of interest. You will also initialize the tables in your database to hold the data for your objects of interest.\n",
    "\n",
    "In general, the sections of this notebook can be run separately from each other. However, you'll want to update and run the parameter defining cell before jumping ahead to other sections. If you get an error stating that something has not been defined, it means you probably need to return to the parameters cell and run it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define database and structural information\n",
    "\n",
    "# database info\n",
    "database_name = 'demo'\n",
    "\n",
    "# path to find data\n",
    "\n",
    "FILE_PATH = '/data/'\n",
    "\n",
    "# Subcellular structures of interest. We recommend keeping all names in letters only \n",
    "# and avoiding upper-case letters. You should keep your smFISH images named 'rna'\n",
    "# These names should match the sub-folders in your data folder\n",
    "structures = ['rna', 'centrosomes']\n",
    "\n",
    "\n",
    "# Each structure folder should have two sub-folders, 'raw-data' and 'segmentations'\n",
    "# You can use different names for these folders if you like -- but update the variables below \n",
    "# if you do\n",
    "\n",
    "raw_data_dir = 'raw-data'\n",
    "segmentation_dir = 'segmentations'\n",
    "\n",
    "# If your segmentation files have a different suffix than your raw data files, \n",
    "# update the variable below with the suffix\n",
    "# The suffix below is the suffix that is generated by the Allen Cell Segmenter batch segmentation process\n",
    "# If your segmentation files have the same suffix as your raw data filenames, then change this variable \n",
    "# to an empty string, e.g. segmentation_file_suffix = ''\n",
    "\n",
    "segmentation_file_suffix = '_struct_segmentation.tiff'\n",
    "\n",
    "\n",
    "# Update the scale parameters below for the number of microns per pixel in the xy plane and the z plane\n",
    "xy_scale = 0.065 # microns per pixel in the xy dimension\n",
    "z_scale = 0.25   # microns between each z step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database for your experiment\n",
    "# Only needs to be run once - will throw an error if run multiple times, since the database won't be overwritten\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+os.environ['POSTGRES_DB'])\n",
    "conn.autocommit = True\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(sql.SQL(\"CREATE DATABASE {database}\").format(database=sql.Identifier(database_name)))\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object data extraction\n",
    "\n",
    "These cells extracts basic data about the subcellular structure objects and insert it into the postgres database.\n",
    "\n",
    "**Note that images are not reprocessed.**\n",
    "\n",
    "If you need to delete object data for a structure in a particular image, use the `delete_data_db(image_name, structure, database_name)` function\n",
    "\n",
    "In a new cell, you would run:\n",
    "```bash\n",
    "from pipeline import delete_data_db\n",
    "image_name = ''\n",
    "structure = ''\n",
    "delete_data_db(image_name, structure, database_name)\n",
    "```\n",
    "Update the image_name and structure variables with the respective image names and structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Functions from the pipeline.py module\n",
    "from pipeline import create_postgres_table, test_data_db, extract_object_properties, insert_object_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates postgres tables to hold data for the structures of interest\n",
    "# Table names are automatically assigned based on your structures of interest\n",
    "\n",
    "for structure in structures:\n",
    "    create_postgres_table(structure, database_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell navigates through the files in your data directories and extracts basic object data such as \n",
    "# area and integrated intensity for each structure \n",
    "\n",
    "for structure in structures:\n",
    "    print(structure)\n",
    "    \n",
    "    segmentations_path = os.path.join(FILE_PATH, structure, segmentation_dir)\n",
    "\n",
    "    for seg_img_name in os.listdir(segmentations_path):\n",
    "        if not seg_img_name[0] == '.':\n",
    "\n",
    "            ins_img_name = seg_img_name\n",
    "\n",
    "            if segmentation_file_suffix:\n",
    "                ins_img_name = seg_img_name[0:-(len(segmentation_file_suffix))] + '.tif'\n",
    "\n",
    "            # check if the image has been processed\n",
    "\n",
    "            \n",
    "            if test_data_db(ins_img_name, structure, database_name):\n",
    "                print('{structure} data for {image_name} has already been processed and will not be re-processed'.format(structure=structure, image_name=ins_img_name))\n",
    "\n",
    "            else:\n",
    "                seg_img_path = os.path.join(segmentations_path, seg_img_name)\n",
    "                ins_img_path = os.path.join(FILE_PATH, structure, raw_data_dir, ins_img_name)\n",
    "\n",
    "                # extract the object properties for that image\n",
    "                object_data_list = extract_object_properties(seg_img_path, ins_img_path, ins_img_name, xy_scale, z_scale)\n",
    "\n",
    "                # save data to database\n",
    "                insert_object_data(structure, object_data_list, database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distances between two subcellular structures\n",
    "\n",
    "Below, you will define two subcellular structures. Structure 1 is the \"object of interest.\" For a given image, each structure 1 object will be measured for how far it is to each structure 2 object in the same image. The closest structure 2 object will be identified and the distance to that object will be recorded in the database. \n",
    "\n",
    "You will define which objects you are interested in distance measurements for. Do you want to know how far away the RNA is from the closest centrosome, nucleus, etc? If you want to do measure distances from RNA to more than one subcellular object, then you would repeat this process in a separate cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import for distance measurements\n",
    "\n",
    "\n",
    "# local packages\n",
    "from pipeline import measure_distance_by_obj, add_distance_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the parameters \n",
    "\n",
    "# define which structures to measure between\n",
    "# Format is: (structure_1, structure_2), where each structure_1 object will be measured for\n",
    "# the shortest distance to structure_2\n",
    "# You can include multiple pairs of structures to measure between \n",
    "# e.g. [('rna', 'centrosomes'), ('rna', 'nuclei')] would measure the distance\n",
    "# for each rna object to the nearest centrosome and the nearest nucleus\n",
    "\n",
    "structure_measurement_tuples = [('rna', 'centrosomes')]\n",
    "\n",
    "\n",
    "# variable to determine if parallel processing is used\n",
    "parallel_processing_bool = True\n",
    "\n",
    "# variable to determine number of objects to measure using surface-to-surface measurements\n",
    "# increase this number if both subcellular structures that are measured are densely packed\n",
    "# if at least one object is sparsely distributed, you can decrease this number\n",
    "number_centroid_measure = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for structure_tuple in structure_measurement_tuples:\n",
    "    structure_1 = structure_tuple[0]\n",
    "    structure_2 = structure_tuple[1]\n",
    "\n",
    "    print('Measuring distances between ' + structure_1 + ' and ' + structure_2)\n",
    "\n",
    "    add_distance_columns(structure_1, structure_2, database_name)\n",
    "\n",
    "    measure_distance_by_obj(structure_1, structure_2, parallel_processing_bool, number_centroid_measure, database_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an images table with metadata for each image\n",
    "\n",
    "Your raw-data images folder likely contains images of a control RNA or control biological condition together with images from your experimental condition. You may also have multiple biological replicates. You can use postgres to help track where each image comes from -- e.g. is it an image of control RNA or an experimental RNA?\n",
    "\n",
    "We recommend storing these data in a .csv file. You can create this file using Excel and then \"Save As\" .csv (you specifically want the \"Comma Separated Values\" file type and not the \"CSV UTF-8\" file type). You can then load the .csv file into postgres using the code below:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "# path to the directory containing your csv file\n",
    "FILE_PATH = '/data/'\n",
    "\n",
    "# name of your csv file\n",
    "csv_name = 'raw-data-metadata.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data into pandas dataframe from csv \n",
    "csv_filepath = os.path.join(FILE_PATH, csv_name)\n",
    "\n",
    "image_df = pd.read_csv(csv_filepath)\n",
    "\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create postgres connection\n",
    "engine = create_engine('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "\n",
    "\n",
    "# save the data to the postgres database\n",
    "# this will overwrite an existing table with this \n",
    "image_df.to_sql('images', con=engine, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize single molecule fluorescence data - optional\n",
    "\n",
    "Here we provide a generalizable tool to estimate the number of molecules per object for single molecule fluorescence data.\n",
    "\n",
    "We apply this tool in this example to normalize single molecule RNA FISH data. We recommend that you have a column in your images table that details the type of single molecule data, which allows you to normalize the single molecule separately for different biological species. If you only have one biological condition, you should still include this table, but fill in only one biological type. \n",
    "\n",
    "The key to this technique is to have a way to identify single molecules from your collection of objects. We use the volume of the object, and have empirically determined that single molecules of our smFISH data typically contain between 20 and 100 pixels. This threshold will be based on your imaging parameters and your optical system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "# name of the table that contains your single molecule data. \n",
    "single_molecule_table = 'rna'\n",
    "\n",
    "# the average integrated intensity is calculated for each rna_type\n",
    "single_molecule_type_column = 'rna_type'\n",
    "\n",
    "# these thresholds identify single molecules using the area feature\n",
    "# of each object\n",
    "# You will need to define these thresholds empirically, based on your data\n",
    "lower_threshold = 20\n",
    "upper_threshold = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first add a column for the normalized intensity data to your structure table of interest\n",
    "\n",
    "\n",
    "add_normalized_col = sql.SQL(\"\"\"ALTER TABLE {single_molecule_table} \n",
    "                                ADD COLUMN IF NOT EXISTS normalized_intensity REAL;\"\"\").format(\n",
    "                                    single_molecule_table = sql.Identifier(single_molecule_table))\n",
    "\n",
    "conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(add_normalized_col)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the single molecule types types from the database\n",
    "\n",
    "single_molecule_type_query = sql.SQL(\"\"\"SELECT DISTINCT ({single_molecule_type_column}) \n",
    "                            FROM images;\"\"\").format(\n",
    "                                single_molecule_type_column=sql.Identifier(single_molecule_type_column))\n",
    "\n",
    "conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(single_molecule_type_query)\n",
    "single_molecule_types =  [single_molecule_type[0] for single_molecule_type in cur.fetchall()]\n",
    "\n",
    "cur.close()\n",
    "conn.close\n",
    "\n",
    "print('The single molecule types in your database are:\\n' + str(single_molecule_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this query calculates the average total intensity of objects between the upper and lower thresholds set in the \n",
    "# parameters column. It then divides every value in the total intensity column by this average and sets the \n",
    "# normalized intensity column to this result\n",
    "\n",
    "\n",
    "for single_molecule_type in single_molecule_types:\n",
    "    normalization_sql = sql.SQL(\"\"\"UPDATE {single_molecule_table} \n",
    "    SET normalized_intensity = total_intensity / \n",
    "    (SELECT avg({single_molecule_table}.total_intensity) FROM {single_molecule_table}\n",
    "                                                    INNER JOIN images \n",
    "                                                    ON {single_molecule_table}.name = images.name \n",
    "                                                    WHERE images.{single_molecule_type_column} = %(single_molecule_type)s\n",
    "                                                    AND {single_molecule_table}.area >= %(lower_threshold)s\n",
    "                                                    AND {single_molecule_table}.area < %(upper_threshold)s) \n",
    "    FROM images \n",
    "    WHERE {single_molecule_table}.name = images.name \n",
    "    AND images.{single_molecule_type_column} = %(single_molecule_type)s \n",
    "    AND {single_molecule_table}.area >= %(lower_threshold)s;\"\"\").format(\n",
    "                    single_molecule_table=sql.Identifier(single_molecule_table),\n",
    "                    single_molecule_type_column=sql.Identifier(single_molecule_type_column))\n",
    "    \n",
    "    conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(normalization_sql, {'single_molecule_type' : single_molecule_type, 'lower_threshold': lower_threshold, 'upper_threshold': upper_threshold})\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROCESSING :\n",
    "\n",
    "In this section, we provide tools to calculate the % of RNA relative to distance and the cumulative % of RNA relative to distance.\n",
    "\n",
    "The first step is to set parameters, which are required for both calculations. If you have single molecule data and want to calculate the % of structure_1 in objects that contain at least *x* number of molecules, then you would set `granule_bool = True` and `granule_threshold = x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "# update the strings that describe your structures of interest\n",
    "# for every structure 1 object, the closest distance to a structure 2 object is measured\n",
    "\n",
    "structure_1 = 'rna'\n",
    "structure_2 = 'centrosomes'\n",
    "\n",
    "# update the column name in your images table that holds data for your image names\n",
    "image_name_column = 'name'\n",
    "\n",
    "# the step size between % structure_1 measurements; in microns\n",
    "step_size = 0.05\n",
    "\n",
    "# optional: distance threshold\n",
    "distance_threshold = 5\n",
    "\n",
    "# Optional: if desired, pipeline will calculate % of structure 1 objects that contain > a user-defined \n",
    "# threshold at each increment. If you set granule_bool = True, you should have single molecule normalized data\n",
    "# in your structure_1 table\n",
    "\n",
    "granule_bool = True\n",
    "granule_threshold = 4\n",
    "\n",
    "# parameters for saving data. Default is to save in the directory containing your raw-data\n",
    "# and segmentations in a folder named data within a folder named output \n",
    "\n",
    "csv_output_dir = os.path.join(FILE_PATH, 'output', 'data')\n",
    "\n",
    "# make an output directory if it doesn't already exist\n",
    "\n",
    "if not os.path.isdir(csv_output_dir):\n",
    "    os.makedirs(csv_output_dir)\n",
    "\n",
    "\n",
    "print(\"The directory where distribution data will be saved is:\\n\" + csv_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculate % of structure 1 relative to distance from structure 2\n",
    "\n",
    "In this section, we calculate the distribution of structure 1 relative to the distance from a subcellular structure of interest. \n",
    "\n",
    "We work with fractions of structure 1 relative to the total fluorescence for structure 1. This approach normalizes for differences in intensity. \n",
    "\n",
    "An optional threshold can be provided for the upper distance threshold. \n",
    "\n",
    "For users with normalized single molecule data, the % of structure 1 in objects > a user-defined threshold relative to distance can also be calculated. Set granule_bool = True and granule_threshold = desired_threshold (e.g. 4) to include this calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import calculate_fraction_rna, save_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_1_distribution_df = calculate_fraction_rna(structure_1, structure_2, image_name_column, distance_threshold, granule_bool, granule_threshold, database_name)\n",
    "\n",
    "structure_1_distribution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we save this csv for later plotting and visualization\n",
    "# note that the file will not be overwritten\n",
    "\n",
    "save_csv('fraction_' + structure_1 + '_per_distance.csv', csv_output_dir, structure_1_distribution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cumulative % of structure 1 relative to distance from structure 2\n",
    "\n",
    "In this section, we calculate the cumulative distribution of structure 1 relative to the distance from a subcellular structure of interest. \n",
    "\n",
    "This workflow will calculate the % of total fluorescence for structure 1 at 0 microns and then at regular intervals defined by the \"step_size\" parameter up to the distance threshold, if you choose to use a distance threshold. For example, if distance_threshold = 5 and the step_size = 0.05, then this code will calculate the % RNA and % RNA in granules at 0, 0.05, 0.10, 0.15 microns, etc., up to 5 microns for each image.\n",
    "\n",
    "If you choose not to define an upper distance threshold, then the % of RNA is calculated at intervals defined by the step size from 0 microns up to the maximum distance_from_structure_2 for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local packages\n",
    "from pipeline import calculate_distributions_by_image, save_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cumulative distributions and store in a dataframe \n",
    "# this calculation can take about 15 minutes per image (depending on the density of data for structure 1)\n",
    "\n",
    "structure_1_distribution_df = calculate_distributions_by_image(distance_threshold, granule_bool, granule_threshold, step_size, image_name_column, structure_1, structure_2, database_name)\n",
    "\n",
    "structure_1_distribution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we save the cumulative percentage for later plotting and visualization\n",
    "# files will not be overwritten\n",
    "\n",
    "save_csv('cumulative_structure_1_per_distance.csv', csv_output_dir, structure_1_distribution_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION :\n",
    "\n",
    "This section provides code to visualize your data. Plots can be saved for publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# define the names of your cumulative distribution data and fractional distribution data\n",
    "fractional_distribution_data_filename = 'fraction_structure_1_per_distance.csv'\n",
    "cumulative_distribution_data_filename = 'cumulative_structure_1_per_distance.csv'\n",
    "\n",
    "# define your output directories\n",
    "data_output_dir = os.path.join(FILE_PATH, 'output', 'data')\n",
    "plots_output_dir =  os.path.join(FILE_PATH, 'output', 'plots')\n",
    "\n",
    "# make a plots output directory if it doesn't already exist\n",
    "if not os.path.isdir(plots_output_dir):\n",
    "    os.makedirs(plots_output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a function to save your plots. We choose to save at 600 dpi as .pdf files, which work well with\n",
    "# Adobe Illustrator files for figure creation. You can change this function so as desired so that your plots will\n",
    "# be saved consistently\n",
    "\n",
    "def save_plot(plot_fn, plots_output_dir, plot):\n",
    "    \"\"\" This function takes two strings as inputs and a matplotlib plot object. plot_fn describes the desired filename\n",
    "    plots_output_dir is the directory to save the plot. plot is a variable containing your plot\n",
    "    \n",
    "    This function will not overwrite data\n",
    "    \n",
    "    The function tests if a file exists in the plots_output_dir. If a file exists, it prints a message and does nothing\n",
    "    If a file does not a exist, the plot is saved\n",
    "    \n",
    "    Returns nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isfile(plots_output_dir + '/' + plot_fn):\n",
    "        print('Plot already saved and will not be saved again')\n",
    "    else:\n",
    "        plot.savefig(plots_output_dir + '/' + plot_fn, bbox_inches = 'tight', dpi = 600, format = 'pdf', transparent = True)\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from your csv file. This appraoch allows you to avoid re-calculating the distributions each time you \n",
    "# want to plot your data, which is time consuming\n",
    "# We'll start with the fractional distribution data \n",
    "\n",
    "fractional_distribution_df = pd.read_csv(data_output_dir + '/' + fractional_distribution_data_filename)\n",
    "fractional_distribution_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the % RNA distribution at each distance as mean (dark line) +/- sd (shading) using the Seaborn library and matplotlib\n",
    "# https://seaborn.pydata.org/examples/index.html\n",
    "# There are a lot of options in Seaborn. In this example, we separate the plots into columns based on the variable \n",
    "# \"cycle\" and adjust the color using the rna_type, in order to compare our experimental RNA (cen) to control (gapdh)\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_distance', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = fractional_distribution_df);\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use your function to save the plot\n",
    "\n",
    "save_plot('fractions_structure_1.pdf', plots_output_dir, fractions_structure_1_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we adjust the plot's x-axis range to 0 - 0.5 micrometers, to emphasize the enrichment of cen near centrosomes\n",
    "# this is achieved using the plt.xlim(0,0.5) code\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_distance', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = fractional_distribution_df);\n",
    "\n",
    "plt.xlim(0, 0.5)\n",
    "plt.ylim(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot \n",
    "\n",
    "save_plot('fractions_structure_1_less-than-0.5.pdf', plots_output_dir, fractions_structure_1_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL -- for those with normalized single molecule data, you can plot the distribution of granule data\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_granule_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_granule', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = fractional_distribution_df);\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot \n",
    "\n",
    "save_plot('fractions_granule_structure_1.pdf', plots_output_dir, fractions_granule_structure_1_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can reset the x scale to better visualize\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_granule_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_granule', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = fractional_distribution_df);\n",
    "\n",
    "plt.xlim(0, 0.5)\n",
    "plt.ylim(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot \n",
    "\n",
    "save_plot('fractions_granule_structure_1-less-than-0.5.pdf', plots_output_dir, fractions_granule_structure_1_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can repeat the same plotting process for the cumulative distribution data\n",
    "# We adjust the name of the csv file for data import\n",
    "\n",
    "cumulative_distribution_df = pd.read_csv(data_output_dir + '/' + cumulative_distribution_data_filename)\n",
    "cumulative_distribution_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative distribution \n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_total_structure_1', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = cumulative_distribution_df);\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the x axis to focus on the near centrosome area\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_total_structure_1', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = cumulative_distribution_df);\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative distribution for objects containing > 4 molecules of RNA (\"granules\")\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_granule_structure_1', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = cumulative_distribution_df);\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the x-axis \n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_granule_structure_1', \n",
    "                                        hue = 'rna_type', \n",
    "                                        col = 'cycle', \n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = cumulative_distribution_df);\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finally, we sometimes find that we want to capture data for a single distance point\n",
    "# For example, we might want to get all the data points for what % of structure is located within 1 micron of structure 2\n",
    "# To do this, we change the subset to distance == 1\n",
    "# Here, we use distance == 0 to capture the % of structure 1 that overlaps w/ structure 2\n",
    "# Since our dataframe contains cumulative distribution data, this point represents the % RNA / % RNA in granules\n",
    "# within 1 micron\n",
    "\n",
    "# this line creates a new dataframe containing only datapoints where the distance is equal to 0\n",
    "zero_micron_df = cumulative_distribution_df.loc[cumulative_distribution_df['distance'] == 0] \n",
    "\n",
    "zero_micron_df['rna cycle'] = zero_micron_df['rna_type'] + ' ' + zero_micron_df['cycle']\n",
    "\n",
    "# verify that the distance column is all 0.0\n",
    "zero_micron_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will plot the percent of RNA at 0 micron as a dot plot with an overlaying box plot \n",
    "# In this example we plot the interphase data only\n",
    "# Note that you can choose to save any of the plots using the save_plot function that you defined earlier\n",
    "\n",
    "ax = sns.swarmplot(x = 'rna cycle', \n",
    "                   y = 'percent_total_structure_1', \n",
    "                   hue = 'rna_type', \n",
    "                   dodge = False,\n",
    "                   order = ['cen interphase', 'gapdh interphase', 'cen metaphase', 'gapdh metaphase'],\n",
    "                   data = zero_micron_df)\n",
    "\n",
    "ax = sns.boxplot(x = 'rna cycle', \n",
    "                 y = 'percent_total_structure_1', \n",
    "                 color = \"0.25\", \n",
    "                 showbox = True, \n",
    "                 fliersize = 0, \n",
    "                 order = ['cen interphase', 'gapdh interphase', 'cen metaphase', 'gapdh metaphase'],\n",
    "                 dodge = False, \n",
    "                 data = zero_micron_df)\n",
    "\n",
    "# make the boxplot clear and the boundaries black\n",
    "for i,box in enumerate(ax.artists):\n",
    "    box.set_edgecolor('black')\n",
    "    box.set_facecolor('white')\n",
    "\n",
    "    # iterate over whiskers and median lines\n",
    "    for j in range(6*i,6*(i+1)):\n",
    "         ax.lines[j].set_color('black')\n",
    "    \n",
    "# set the y axis from 0 to 100\n",
    "plt.ylim(0,100)\n",
    "\n",
    "# make the x and y axes visible w/o the top and right frames\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "# remove the legend frame\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "zero_micron_plt = ax.get_figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_one_micron_total_RNA_fn = 'percent_total_RNA_at_0_micron.pdf'\n",
    "\n",
    "save_plot(subset_one_micron_total_RNA_fn, plots_output_dir, zero_micron_plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save database tables as .csv files\n",
    "\n",
    "This section gives you the option to save your database tables as .csv files, which allows you to view raw object data using a text editor rather than needing to have a specialized program like postgres.\n",
    "\n",
    "By default, the data will be saved in the output/db_backups/db_csvs folder. You can change this behavior in the parameters cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql \n",
    "import os\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "db_csv_output_dir =  os.path.join(FILE_PATH, 'output', 'db_backups', 'db_csvs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make folders to contain csv files if they do not already exist \n",
    "\n",
    "if not os.path.isdir(db_csv_output_dir):\n",
    "    os.makedirs(db_csv_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell gets the names of the tables you created from the postgres database\n",
    "\n",
    "select_tables_sql = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\"\n",
    "\n",
    "conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "cur = conn.cursor()\n",
    "cur.execute(select_tables_sql)\n",
    "table_name_raw = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "table_names = [table_name[0] for table_name in table_name_raw]\n",
    "\n",
    "print('These are the names of your tables to be saved as .csv files:\\n' + str(table_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell copies data from those tables into csv files\n",
    "# it will overwrite your previously saved files\n",
    "\n",
    "for table_name in table_names:\n",
    "    table_fn = date.today().strftime('%Y.%m.%d-') + database_name + '-' + table_name + '.csv'\n",
    "    table_path = os.path.join(db_csv_output_dir, table_fn)\n",
    "\n",
    "    copy_sql_query = sql.SQL(\"COPY {table_name} TO STDOUT WITH CSV HEADER\").format(table_name = sql.Identifier(table_name))\n",
    "\n",
    "    conn = psycopg2.connect('postgresql://'+os.environ['POSTGRES_USER']+':'+os.environ['POSTGRES_PASSWORD']+'@'+\"db\"+':'+'5432'+'/'+database_name)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "\n",
    "    with open(table_path, 'w') as f_output:\n",
    "        cur.copy_expert(copy_sql_query, f_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
