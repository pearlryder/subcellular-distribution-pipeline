{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground 7:  Segmentation workflow for Connexin-43\n",
    "\n",
    "This notebook contains the workflow for connexin-43, and serves as a starting point for developing a classic segmentation workflow if your data shows similar morphology as connexin-43.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [Connexin-43](https://www.allencell.org/cell-observations/category/connexin43)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Auto-Contrast intensity normalization\n",
    "* 2D Gaussian smoothing slice by slice\n",
    "* 3D Spot filter \n",
    "* Size thresholding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage   \n",
    "import imageio\n",
    "\n",
    "# function for core algorithm\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_slice_by_slice\n",
    "from skimage.morphology import remove_small_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 30, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Update the path to your data\n",
    "\n",
    "FILE_PATH = '/data/centrosomes/raw-data/'\n",
    "\n",
    "FILE_NAME = 'NC12_interphase_Slide22_Emb21_Img1.tif'\n",
    "\n",
    "reader = AICSImage(FILE_PATH + FILE_NAME) \n",
    "IMG = reader.data\n",
    "\n",
    "print(IMG.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9e658f2cf44e20a7f8890c0b9d9dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkImageF3 *' at 0x7fe918…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################\n",
    "structure_channel = 0\n",
    "#####################\n",
    "\n",
    "structure_img = IMG[0, 0, structure_channel,:,:,:]\n",
    "view(single_fluorescent_view(structure_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter:  `intensity_scaling_param = [1, 40]`\n",
    "\n",
    "\n",
    "* **Smoothing**: 2D gaussian smoothing slice by slice with `gaussian_smoothing_sigma = 1`.  The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: normalize into [mean - 1 x std, mean + 40 x std] \n",
      "intensity normalization completes\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "intensity_scaling_param = [1, 40]\n",
    "gaussian_smoothing_sigma = 1\n",
    "################################\n",
    "\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with 2d gaussian filter slice by slice \n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f129802364b4c7a87d37d9fa1f0becf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(gradient_opacity=0.22, rendered_image=<itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "We have a function to give you some suggestions. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 439.550545981796\n",
      "the standard deviation of intensity of the stack: 76.74768376282486\n",
      "0.9999 percentile of the stack intensity is: 4049.0\n",
      "minimum intensity of the stack: 350\n",
      "maximum intensity of the stack: 4049\n",
      "suggested upper range is 47.0, which is 4046.6916828345647\n",
      "suggested lower range is 1.0, which is 362.80286221897114\n",
      "So, suggested parameter for normalization is [1.0, 47.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "from aicssegmentation.core.pre_processing_utils import suggest_normalization_param\n",
    "suggest_normalization_param(struct_img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply 3D Spot filter (S3)\n",
    "\n",
    "Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "* `scale_x` is set based on the estimated radius of your target dots. For example, if visually the diameter of the dots is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have dots of very different sizes.  \n",
    "* `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf more dots and fatter segmentation, while larger `cutoff_x` could be less permisive and yield less dots and slimmer segmentation. \n",
    "\n",
    "Parameter:  `s3_param = [[1, 0.031]]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s3_param = [[1, 0.031]]\n",
    "################################\n",
    "\n",
    "bw = dot_3d_wrapper(structure_img_smooth, s3_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5022b2f306c34dc3953568c0e790a2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(gradient_opacity=0.22, rendered_image=<itkImagePython.itkImageUC3; proxy of <Swig Object of type 'itkIm…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the segmentation result\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd50a7a0f814f89a045893506a5606c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(gradient_opacity=0.22, rendered_image=<itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw,roi=['ROI',viewer_bw.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(struct_img,bw,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the segmentation satisfactory? Here are some possible criteria:\n",
    "\n",
    "------------------\n",
    "* Is there any spot should be detected but not? Try to reduce `cutoff_x`\n",
    "* Is there any spot should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented size of the spots fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any spot that should be solid but segmented as a ring? Try to increase `scale_x`\n",
    "* Are you observing spots with very different sizes? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "--------------------\n",
    "\n",
    "#### If the results are satisfactory, go to next step; otherwise, try to tweak the parameters based on the above suggestions. \n",
    "\n",
    "Assumption: the segmentation result is saved in a variable named `bw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 5\n",
    "################################\n",
    "\n",
    "seg = remove_small_objects(bw>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c7cc19f2894dec9a974982c874ba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(gradient_opacity=0.22, rendered_image=<itkImagePython.itkImageUC3; proxy of <Swig Object of type 'itkIm…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viewer_final = view(segmentation_quick_view(seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a422e13c099f4bf98c898ed43a4c00f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(gradient_opacity=0.22, rendered_image=<itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,474, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a ome.tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save your test segmentations\n",
    "\n",
    "output_filepath = '/output/test-segmentations/'\n",
    "\n",
    "if not os.path.isdir(output_filepath):\n",
    "    os.makedirs(output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file will be saved within your docker container volume \"output\"\n",
    "# in order to visualize this most easily, you can copy this to your computer using\n",
    "# docker cp jupyter:/output/ output/ \n",
    "\n",
    "output_seg = final_seg>0\n",
    "out=output_seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "imageio.volwrite(output_filepath + FILE_NAME + '-test_seg.tiff', out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
