{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground:  Segmentation workflow for RNA\n",
    "\n",
    "This notebook contains the workflow to detect single-molecule RNA FISH signals that works well for us. It is based off the Allen Cell Segmenter workflow for sialyltransferase 1. \n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Auto-Contrast intensity normalization\n",
    "* Background subtraction\n",
    "* Edge-reserving smoothing\n",
    "* 3D Spot filter \n",
    "* Watershed algorithm to split adjacent objects\n",
    "* Size thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO packages\n",
    "from aicsimageio import AICSImage\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# calculation packages\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# segmentation packages\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_slice_by_slice\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper\n",
    "from skimage.morphology import dilation, ball, remove_small_objects\n",
    "\n",
    "# watershed packages\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.measure import label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We'll start by investigating the segmentation for a single image. You can change which image you're investigating using the FILE_NAME variable below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the path to your data\n",
    "# For those on a Mac system, you can update your username\n",
    "\n",
    "\n",
    "FILE_PATH = '/data/rna/raw-data/'\n",
    "\n",
    "FILE_NAME = 'NC12_interphase_Slide22_Emb21_Img1.tif'\n",
    "\n",
    "reader = AICSImage(FILE_PATH + FILE_NAME) \n",
    "IMG = reader.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "structure_channel = 0\n",
    "#####################\n",
    "\n",
    "structure_img0 = IMG[0, 0, structure_channel,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143b2a7d488f41228660ac9a7ead1396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkImageF3 *' at 0x7f84c9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(single_fluorescent_view(structure_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for st6gal1:  `intensity_scaling_param = [9, 19]`\n",
    "\n",
    "\n",
    "* **Smoothing**: 3D gaussian smoothing with `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# First, calculate the best intensity normalization parameters\n",
    "\n",
    "minimum_value = np.amin(structure_img0)\n",
    "mean_value = np.mean(structure_img0)\n",
    "percentile_99 = np.percentile(structure_img0, 99.99)\n",
    "std_array = np.std(structure_img0)\n",
    "\n",
    "a = round((mean_value - minimum_value) / std_array, 1)\n",
    "b = round((percentile_99 - mean_value) / std_array, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETER ##\n",
    "intensity_scaling_param = [a, b]\n",
    "gaussian_smoothing_sigma = 0.5\n",
    "################################\n",
    "\n",
    "# intensity normalization\n",
    "structure_img = intensity_normalization(structure_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with gaussian filter\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(structure_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75682f9b490b4302b1fc8449a661196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkImageF3 *' at 0x7f84c8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quickly visualize the image after smoothing\n",
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "The Allen Cell Segmenter has a function to give you some suggestions for the normalization parameters. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = ` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.1: Apply 3D Spot filter (S3)\n",
    "\n",
    "Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "* `scale_x` is set based on the estimated radius of your target dots. For example, if visually the diameter of the dots is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have dots of very different sizes.  \n",
    "* `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf more dots and fatter segmentation, while larger `cutoff_x` could be less permisive and yield less dots and slimmer segmentation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s3_param = [[1, 0.005], [10, 0.1]]\n",
    "################################\n",
    "\n",
    "bw = dot_3d_wrapper(structure_img_smooth, s3_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6694f8749d054933ad4c9648f884b424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageUC3; proxy of <Swig Object of type 'itkImageUC3 *' at 0x7f84…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the segmentation result\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad500ee354142b5a68a08df87662836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(rendered_image=<itk.itkImagePython.itkImageF3; proxy of <Swig Object of type 'itkImageF3 *' at 0x7f84c8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(structure_img0,bw,roi=['ROI',viewer_bw.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(structure_img0,bw,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the above segmentation is satisfactory? Here are some possible things to check:\n",
    "\n",
    "-------\n",
    "* Is there big missing chunk? Or are segmented chunks are significantly fatter? You may visualize the intermediate result, i.e. the objects, by `view(segmentation_quick_view(object_for_debug))`. By doing this, you can have some sense whether the objects are roughly regions in individual cells. In other words, we want to roughly isolate the stuffs in individual cells. If not, you may change `global_thresh_method`. Three options `'tri'`, `'med'`,`'ave'` are implemented. `'tri'` is triangle method, `'med'` is median method, `'ave'` is the average of the values returned by triangle method and median method. \n",
    "* Observing missing chunks may be also due to falsely removed objects. Try to decrease `object_minArea` to be more permisive in segmenting objects.\n",
    "* Do you observe a chunk of background stuffs in the segmentation? Try to increase `object_minArea` to exclude these background noise. \n",
    "* If you observe the segmented objects are slightly fatter than the actual size (may take defraction of light into consideration), don't worry, Next step (2.2) can help the make them thinner. \n",
    "* If you observe missing dots in the segmentation, don't worry. Later step (2.3) can pick them up.\n",
    "--------\n",
    "\n",
    "#### If the results are satisfactory, go to Step 2.2 directly; otherwise, try to tweak the parameters based on the above suggestions. \n",
    "\n",
    "Assumption: the segmentation result is saved in a variable named `bw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.2: Use watershed algorithm to separate touching dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minArea = 20\n",
    "\n",
    "local_maxi = peak_local_max(structure_img0, min_distance=5, labels=label(bw), indices=False)\n",
    "distance = distance_transform_edt(bw)\n",
    "im_watershed = watershed(-distance, label(dilation(local_maxi, selem=ball(1))), mask=bw, watershed_line=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing \n",
    "Remove all objects smaller than the defined minimum area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for removing small objects ##\n",
    "minArea = 20\n",
    "################################\n",
    "\n",
    "final_seg = remove_small_objects(im_watershed>0, min_size=minArea, connectivity=1, in_place=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_final = view(segmentation_quick_view(final_seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(structure_img0, final_seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,474, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a .tiff image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where to save your test segmentations\n",
    "\n",
    "output_filepath = '/output/test-segmentations/'\n",
    "\n",
    "if not os.path.isdir(output_filepath):\n",
    "    os.makedirs(output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file will be saved within your docker container volume \"output\"\n",
    "# in order to visualize this most easily, you can copy this to your computer using\n",
    "# docker cp jupyter:/output/ output/ \n",
    "\n",
    "output_seg = final_seg>0\n",
    "out=output_seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "imageio.volwrite(output_filepath + FILE_NAME + '-test_rna_seg.tiff', out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
